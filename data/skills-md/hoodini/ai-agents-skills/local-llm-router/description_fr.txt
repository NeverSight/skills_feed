Acheminez les requêtes de codage de l'IA vers des LLM locaux dans des réseaux isolés. Intègre Serena MCP pour la compréhension du code sémantique. À utiliser lorsque vous travaillez hors ligne, avec des modèles locaux (Ollama, LM Studio, Jan, OpenWebUI) ou dans des environnements sécurisés/fermés. Déclencheurs sur LLM local, Ollama, LM Studio, Jan, IA hors ligne, Serena, inférence locale, réseau fermé, routage de modèles, réseau de défense, codage sécurisé.
