Cost optimization patterns for LLM API usage â€” model routing by task complexity, budget tracking, retry logic, and prompt caching.
