Guide for LLM security attacks: prompt injection, jailbreaking, data extraction, and where to place resources in README.md.
