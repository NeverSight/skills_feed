Utilice esta habilidad cuando el usuario quiera llamar a diferentes modelos LLM a través de la API unificada de OpenRouter, comparar respuestas de modelos, realizar un seguimiento de costos y tiempos de respuesta, o encontrar el mejor modelo para una tarea. Los desencadenantes incluyen solicitudes para probar modelos, comparar el rendimiento, utilizar proveedores específicos (OpenAI, Anthropic, Google, etc.) u optimizar la velocidad/costo.
