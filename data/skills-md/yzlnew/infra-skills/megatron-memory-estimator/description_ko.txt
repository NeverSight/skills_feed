Megatron 기반 MoE(Mixture of Experts) 및 밀도 모델에 대한 GPU 메모리 사용량을 추정합니다. 사용자가 (1) HuggingFace 모델 구성(DeepSeek-V3, Qwen 등)에서 메모리를 추정하고, (2) 훈련을 위한 GPU 리소스 할당을 계획하고, (3) 다양한 병렬 처리 전략(TP/PP/EP/CP)을 비교하고, (4) 모델이 사용 가능한 GPU 메모리에 적합한지 확인하거나, (5) 메모리 효율성을 위해 훈련 구성을 최적화해야 하는 경우에 사용합니다.
