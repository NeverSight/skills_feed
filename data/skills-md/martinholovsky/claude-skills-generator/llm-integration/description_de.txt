Expertenwissen für die Integration lokaler großer Sprachmodelle mithilfe von llama.cpp und Ollama. Umfasst sicheres Laden von Modellen, Inferenzoptimierung, sofortige Handhabung und Schutz vor LLM-spezifischen Schwachstellen, einschließlich Prompt-Injection, Modelldiebstahl und Denial-of-Service-Angriffen.
