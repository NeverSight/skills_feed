KV キャッシュとプロンプト キャッシュを通じて LLM コストとレイテンシを最適化します。 (1) キャッシュ ヒットに対するプロンプトの構築、(2) Anthropic/Cohere/OpenAI/Gemini の API キャッシュ コントロールの構成、(3) vLLM/SGLang/Ollama を使用したセルフホスト型推論のセットアップ、(4) プレフィックス再利用によるエージェント ワークフローの構築、(5) バッチ処理パイプラインの設計、または (6) キャッシュの価格設定とトレードオフを理解する場合に使用します。
