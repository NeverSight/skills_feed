---
name: paper-digest
description: Generate shareable paper summaries for Discord/Slack/Twitter. Use when user provides arxiv paper(s) and wants a digestible summary to share. Triggers on phrases like "ë…¼ë¬¸ ìš”ì•½", "paper summary", "share this paper", "ë””ìŠ¤ì½”ë“œì— ê³µìœ ", "summarize for sharing". Produces insight-centered single-paragraph summaries that explain WHY research matters, not just WHAT it does.
---

# Paper Digest

Single-paragraph summaries optimized for social sharing. Insight over information.

## Structure

1. **Context**: What's the problem?
2. **Insight**: What did they realize that others missed?
3. **Solution**: How does insight â†’ method? (should feel natural)
4. **Evidence**: Concrete comparison showing it works

Then: Implication line + ğŸ“ arxiv link

## Key Rules

* Explain like reader is smart but unfamiliar with the domain
* Use concrete examples/analogies (e.g., "ì“°ë ˆê¸°í†µ ì—­í• " >> "íŠ¹ì • í† í°ì— ì§‘ì¤‘")
* Show cause-and-effect chains explicitly
* Compare/contrast with alternatives ("X failed while Y succeeded")
* Bold 2-4 key concepts
* Match user's language (Korean/English)

## Example

**Input**: arXiv 2601.15380

**Output**:

Transformerì˜ attentionì€ "ì–´ë–¤ í† í°ì„ ì–¼ë§ˆë‚˜ ë³¼ì§€"ë¥¼ ê²°ì •í•˜ëŠ”ë°, ì´ ë…¼ë¬¸ì€ softmax attentionì„ **Entropic Optimal Transport(EOT)**ë¼ëŠ” ìµœì í™” ë¬¸ì œì˜ í•´ë¡œ ì¬í•´ì„í•œë‹¤. ì´ ê´€ì ì´ ì£¼ëŠ” í†µì°°ì€: attention ê³„ì‚°ì—ëŠ” ì•”ë¬µì ìœ¼ë¡œ "ëª¨ë“  ìœ„ì¹˜ê°€ ë™ë“±í•˜ê²Œ ì¤‘ìš”í•˜ë‹¤"ëŠ” uniform priorê°€ ìˆ¨ì–´ìˆë‹¤ëŠ” ê²ƒì´ë‹¤. ì´ê²Œ ì™œ ë¬¸ì œì¸ê°€? LLMì—ì„œ ì²« ë²ˆì§¸ í† í°ì´ ì˜ë¯¸ì™€ ë¬´ê´€í•˜ê²Œ ì—„ì²­ë‚œ attentionì„ ë°›ëŠ” attention sink í˜„ìƒì´ ìˆë‹¤. SoftmaxëŠ” í•©ì´ 1ì¸ í™•ë¥ ì„ ì¶œë ¥í•´ì•¼ í•˜ë¯€ë¡œ, queryê°€ ë§ˆë•…íˆ ë³¼ í† í°ì´ ì—†ì„ ë•Œ attentionì„ "ë²„ë¦´ ê³³"ì´ í•„ìš”í•œë°, uniform prior í•˜ì—ì„œ ì´ë¥¼ êµ¬í˜„í•˜ë ¤ë©´ ì²« í† í°ì˜ key vectorê°€ "ë‚˜ëŠ” ì“°ë ˆê¸°í†µì´ì•¼"ë¼ëŠ” êµ¬ì¡°ì  ì •ë³´ê¹Œì§€ ë‹´ì•„ì•¼ í•œë‹¤â€”ì›ë˜ semantic contentë§Œ í‘œí˜„í•´ì•¼ í•  keyì˜ í‘œí˜„ë ¥ì´ ë‚­ë¹„ë˜ëŠ” ê²ƒì´ë‹¤. EOT í•´ì„ì´ ì´ ë¬¸ì œë¥¼ ë“œëŸ¬ë‚´ì£¼ì—ˆìœ¼ë¯€ë¡œ, í•´ê²°ì±…ë„ ìì—°ìŠ¤ëŸ½ë‹¤: priorë¥¼ uniformì—ì„œ learnableë¡œ ë°”ê¾¸ë©´ ëœë‹¤. ì´ ë…¼ë¬¸ì´ ì œì•ˆí•˜ëŠ” GOATì€ "ê° ìœ„ì¹˜ì˜ ê¸°ë³¸ ì¤‘ìš”ë„"ë¥¼ ë³„ë„ì˜ í•™ìŠµ ê°€ëŠ¥í•œ í•­ìœ¼ë¡œ ë¶„ë¦¬í•´ì„œ, key vectorëŠ” ìˆœìˆ˜í•˜ê²Œ ì˜ë¯¸ë§Œ, ìœ„ì¹˜ ì •ë³´ëŠ” priorê°€ ë‹´ë‹¹í•˜ê²Œ í•œë‹¤. ì‹¤í—˜ì—ì„œ ê¸°ì¡´ ë°©ë²•ë“¤ì´ í›ˆë ¨ ê¸¸ì´ ì´ˆê³¼ ì‹œ ê¸‰ê²©íˆ ì‹¤íŒ¨í•œ ë°˜ë©´, GOATì€ ê¸´ ë¬¸ë§¥ì—ì„œë„ ì •ë³´ ê²€ìƒ‰ ì„±ëŠ¥ì„ ìœ ì§€í–ˆë‹¤.

**Implication**: EOT ê´€ì ì€ attentionì˜ ìˆ¨ê²¨ì§„ ê°€ì •ì„ ë“œëŸ¬ë‚´ê³ , ê·¸ ê°€ì •ì„ ë°”ê¿€ ìˆ˜ ìˆë‹¤ëŠ” ì„¤ê³„ ììœ ë„ë¥¼ ì—´ì–´ì¤€ë‹¤â€”attention sinkëŠ” uniform priorì˜ ë¶€ì‚°ë¬¼ì´ë©°, priorë¥¼ ëª…ì‹œì ìœ¼ë¡œ ëª¨ë¸ë§í•˜ë©´ í•´ê²°ëœë‹¤.

ğŸ“ https://arxiv.org/abs/2601.15380

## Avoid

* Jargon without intuition
* Findings without comparison to alternatives
* Method description without motivation ("ì™œ ì´ë ‡ê²Œ í–ˆëŠ”ì§€" ì—†ì´ "ì´ë ‡ê²Œ í–ˆë‹¤"ë§Œ)

## Multiple Papers

When summarizing multiple papers:
* Lead with the unifying theme/problem
* Contrast what each paper realized differently
* Synthesize implications across papers

## Language

Match the user's language (Korean/English). Maintain the same insight-first structure regardless of language.
