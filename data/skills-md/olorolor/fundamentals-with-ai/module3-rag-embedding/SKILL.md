---
name: module3-rag-embedding
description: RAG, embedding, vector search를 통해 사내/최신 데이터를 LLM 응답에 연결하는 방법과 선택 기준을 다루는 모듈.
---

# Module 3: RAG and Embedding

핵심 질문: AI에게 우리 데이터를 어떻게 연결할 것인가?

## 학습 목표

- RAG의 흐름(질문→검색→근거 주입→응답)을 설명할 수 있다.
- embedding 기반 검색과 키워드 검색의 차이를 이해한다.
- Prompt Engineering / RAG / Fine-tuning 중 선택 기준을 제시할 수 있다.

## 교차 복습 연결

- Module 1의 hallucination: "환각이 구조적 문제라면, 어떻게 줄일 수 있을까?" → RAG 등장
- Module 2의 context window/chunking: "검색 결과를 context에 넣으려면 공간 관리가 필요하다"

## 진행 구조 (4단계, 목표 10~15분)

이 모듈은 반드시 아래 4단계를 순서대로 진행한다. 단계를 건너뛰지 않는다.

### Phase 1: 문제 도입 (2~3분, 최소 1회 학습자 응답 필요)

- Module 1에서 배운 hallucination을 상기시킨다.
- "회사 내부 문서에 대해 AI가 엉뚱한 답을 하는" 상황을 학습자의 직무에서 끌어낸다.
- "오픈북 시험" 비유를 도입할 수 있지만, 먼저 학습자에게 "어떻게 해결할 수 있을 것 같으세요?" 질문을 던진다.
- 학습자 응답을 받은 후에야 Phase 2로 진행한다.

### Phase 2: 핵심 개념 탐구 (5~7분, 최소 3회 학습자 응답 필요)

아래 개념을 순서대로 다룬다. **한 응답에서 2개 이상의 새로운 개념을 동시에 설명하지 않는다.**

1. **retrieval + grounding** — "검색해서 근거를 붙여주는" RAG의 기본 흐름
2. **chunking + embedding** — 문서를 잘라서 벡터로 바꾸는 과정 (Module 2의 chunking 재등장)
3. **vector search** — 키워드 검색과 의미 기반 검색의 차이

각 개념마다:
- "오픈북 시험" 비유를 확장하여 연결한다.
- ASCII 흐름도로 RAG 파이프라인을 시각화한다.
- 설명 후 반드시 학습자에게 확인 질문을 던지고 **응답을 기다린다**.
- 학습자가 응답한 후에야 다음 개념으로 넘어간다.

### Phase 3: 연결 및 적용 (2~3분, 최소 1회 학습자 응답 필요)

- **Prompt Engineering / RAG / Fine-tuning** 3가지의 트레이드오프를 비교한다.
- 학습자의 직무 상황에 맞는 시나리오를 제시하여 "어떤 방식을 선택하겠는가?" 판단을 요청한다.
- 정답 하나가 아니라 트레이드오프 비교로 마무리한다.
- 학습자의 응답을 받은 후에야 Phase 4로 진행한다.

### Phase 4: 이해 확인 (2~3분, 최소 1회 학습자 응답 필요)

완료 기준 질문을 제시한다. 학습자가 **자신의 언어로** 답해야 한다.

1. 우리 조직 문서 Q&A에는 왜 RAG가 유리한가?
2. Fine-tuning 대신 RAG를 먼저 검토해야 하는 이유는?

- 학습자의 답이 부족하면 Phase 2~3의 관련 부분으로 돌아가 보충한다.
- 충분하면 모듈 완료를 선언하고 다음 모듈을 안내한다.

## 페이스 규칙 (필수)

- **한 응답에서 2개 이상의 새로운 개념을 동시에 설명하지 않는다.**
- **학습자가 응답하지 않은 상태에서 다음 개념으로 넘어가지 않는다.**
- **최소 교환 횟수: AI 6회 응답 + 학습자 6회 응답 = 12턴 이상이어야 모듈 완료 가능.**
- 12턴 미만에서 완료 기준을 충족하더라도, 추가 연결 질문이나 적용 시나리오로 깊이를 확보한다.
- 선택지가 필요한 분기점에서는 `AskUserQuestion` 도구를 사용한다.

## 개념 체계 (기본 → 심화)

### 기본 (반드시 다룸)

| 개념 | 핵심 한 줄 | Phase |
|---|---|---|
| retrieval | 질문과 관련된 문서/정보를 검색하는 단계 | 2 |
| grounding | 검색된 근거를 LLM 응답에 주입하여 환각을 줄이는 기법 | 2 |
| chunking | 문서를 검색 가능한 크기로 분할 (Module 2 재등장) | 2 |
| embedding | 텍스트를 의미를 담은 숫자 벡터로 변환 | 2 |
| vector search | 벡터 간 유사도를 계산하여 의미 기반으로 검색 | 2 |

### 심화 (학습자가 관심을 보이거나, 경험 수준이 높을 때 확장)

| 개념 | 핵심 한 줄 | 언제 다루나 |
|---|---|---|
| hybrid search | 키워드 검색(BM25)과 벡터 검색을 결합하여 정확도 향상 | vector search 이해 후 |
| reranking | 초기 검색 결과를 재순위화하여 상위 결과의 품질 향상 | retrieval 품질에 관심을 보일 때 |
| embedding 모델 선택 | OpenAI, Cohere, 오픈소스 임베딩 모델의 차이와 선택 기준 | embedding을 이해한 후 |
| vector DB 비교 | Pinecone, Weaviate, ChromaDB, pgvector 등 저장소 선택 | "벡터를 어디에 저장하나?" 질문 시 |
| chunking 전략 심화 | 고정 길이, 의미 기반, 재귀적 분할, overlap 전략 | chunking 기본을 이해한 후 |
| Fine-tuning vs RAG 심화 | 데이터 양, 업데이트 주기, 비용, 정확도 트레이드오프 상세 | Phase 3 비교에서 깊이를 원할 때 |
| evaluation (RAG 품질 측정) | retrieval 정확도, 응답 충실도, 근거 일치율 측정 방법 | "RAG가 잘 되는지 어떻게 아나?" 질문 시 |
| knowledge graph + RAG | 그래프 구조와 벡터 검색을 결합한 고급 검색 패턴 | 기본 RAG의 한계를 느낄 때 |

### 심화 개념 진행 규칙

- 기본 개념이 모두 완료된 후에만 심화로 확장한다.
- 학습자가 관심을 보이거나 AI 경험이 높을 때 자연스럽게 도입한다.
- 심화 개념은 Phase 3 또는 Phase 4 이후 보너스로 다루되, 모듈 완료 기준에는 포함하지 않는다.
- 학습자가 원하지 않으면 넘어간다.

## 완료 기준

학습자가 아래 질문에 답하면 완료한다.

1. 우리 조직 문서 Q&A에는 왜 RAG가 유리한가?
2. Fine-tuning 대신 RAG를 먼저 검토해야 하는 이유는?

## 다음 연결

모듈 완료 시 다음 선택지를 `AskUserQuestion` 도구로 제시한다.

- 검색/실행을 자동화하는 흐름은 `module4-agent`
