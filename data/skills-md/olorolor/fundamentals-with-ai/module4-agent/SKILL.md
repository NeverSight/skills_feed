---
name: module4-agent
description: Assistive AI와 Agentic AI의 차이, ReAct 루프, Tool Use, MCP 개념을 학습시키는 모듈.
---

# Module 4: Agent

핵심 질문: AI가 실제로 행동하게 하려면 무엇이 필요한가?

## 학습 목표

- Assistive AI와 Agentic AI의 차이를 설명할 수 있다.
- ReAct(Thought-Action-Observation) 루프를 이해한다.
- Tool Use에서 LLM의 역할(판단)과 시스템 역할(실행)을 구분할 수 있다.
- MCP의 필요성을 설명할 수 있다.

## 교차 복습 연결

- Module 3의 RAG: "RAG는 '검색'까지만 한다. Agent는 검색 결과를 가지고 '실행'까지 한다"
- Module 1의 확률적 생성: "확률적으로 판단하는 AI에게 실행 권한을 주면 어떤 위험이 있을까?"

## 진행 구조 (4단계, 목표 10~15분)

이 모듈은 반드시 아래 4단계를 순서대로 진행한다. 단계를 건너뛰지 않는다.

### Phase 1: 문제 도입 (2~3분, 최소 1회 학습자 응답 필요)

- "추천"과 "실행"의 차이를 학습자의 직무에서 끌어낸다.
- 예: "AI가 회의록을 요약해주는 것 vs AI가 요약 후 캘린더에 일정까지 등록해주는 것"
- 학습자에게 "AI가 직접 실행까지 해주면 좋겠다고 생각한 적 있으세요?" 질문을 던진다.
- 학습자 응답을 받은 후에야 Phase 2로 진행한다.

### Phase 2: 핵심 개념 탐구 (5~7분, 최소 3회 학습자 응답 필요)

아래 개념을 순서대로 다룬다. **한 응답에서 2개 이상의 새로운 개념을 동시에 설명하지 않는다.**

1. **assistive vs agentic** — 답변만 하는 AI vs 행동하는 AI의 차이
2. **ReAct loop + tool calling** — 생각(Thought)→행동(Action)→관찰(Observation) 반복 루프
3. **MCP + human-in-the-loop** — 도구 연결의 표준화와 안전 장치

각 개념마다:
- 단일 호출이 아닌 반복 루프임을 ASCII 흐름도로 시각화한다.
- 설명 후 반드시 학습자에게 확인 질문을 던지고 **응답을 기다린다**.
- 학습자가 응답한 후에야 다음 개념으로 넘어간다.
- 권한/안전 관점의 질문을 반드시 1개 이상 던진다.

### Phase 3: 연결 및 적용 (2~3분, 최소 1회 학습자 응답 필요)

- 학습자의 직무에서 "Agent가 유용할 수 있는 시나리오"를 함께 도출한다.
- Module 1의 확률적 생성을 상기시키며: "확률적으로 판단하는 AI에게 실행 권한을 주면 어떤 위험이 있을까?"
- 학습자에게 위험 시나리오와 완화 방안을 직접 생각하게 한다.
- 학습자의 응답을 받은 후에야 Phase 4로 진행한다.

### Phase 4: 이해 확인 (2~3분, 최소 1회 학습자 응답 필요)

완료 기준 질문을 제시한다. 학습자가 **자신의 언어로** 답해야 한다.

1. 챗봇이 일정 등록을 못 하는 이유 (도구/권한 부재)
2. Agent가 위험해질 수 있는 지점 1가지와 완화 방식

- 학습자의 답이 부족하면 Phase 2~3의 관련 부분으로 돌아가 보충한다.
- 충분하면 모듈 완료를 선언하고 다음 모듈을 안내한다.

## 페이스 규칙 (필수)

- **한 응답에서 2개 이상의 새로운 개념을 동시에 설명하지 않는다.**
- **학습자가 응답하지 않은 상태에서 다음 개념으로 넘어가지 않는다.**
- **최소 교환 횟수: AI 6회 응답 + 학습자 6회 응답 = 12턴 이상이어야 모듈 완료 가능.**
- 12턴 미만에서 완료 기준을 충족하더라도, 추가 연결 질문이나 적용 시나리오로 깊이를 확보한다.
- 선택지가 필요한 분기점에서는 `AskUserQuestion` 도구를 사용한다.

## 개념 체계 (기본 → 심화)

### 기본 (반드시 다룸)

| 개념 | 핵심 한 줄 | Phase |
|---|---|---|
| assistive vs agentic | 답변만 하는 AI vs 도구를 써서 행동하는 AI | 2 |
| ReAct loop | 생각(Thought)→행동(Action)→관찰(Observation) 반복 패턴 | 2 |
| tool calling (function calling) | LLM이 외부 도구/API를 호출하는 인터페이스 | 2 |
| MCP (Model Context Protocol) | 도구 연결을 표준화하는 프로토콜 — USB처럼 규격 통일 | 2 |
| human-in-the-loop | AI 실행 전 사람의 승인/검토를 거치는 안전 장치 | 2 |

### 심화 (학습자가 관심을 보이거나, 경험 수준이 높을 때 확장)

| 개념 | 핵심 한 줄 | 언제 다루나 |
|---|---|---|
| multi-agent 협업 | 여러 Agent가 역할을 나눠 협력하는 패턴 (CrewAI, AutoGen 등) | 단일 Agent를 이해한 후 |
| planning과 reasoning | Agent가 복잡한 작업을 하위 단계로 분해하는 능력 | ReAct loop 이해 후 |
| memory (short-term / long-term) | Agent가 이전 대화/작업을 기억하고 활용하는 메커니즘 | Agent의 한계를 느낄 때 |
| guardrails / safety layer | 입출력 필터링, 권한 제한, 위험 행동 차단 메커니즘 | human-in-the-loop 후 보안에 관심 시 |
| agent 평가 (eval) | Agent 성능 측정 — 작업 완료율, 정확도, 비용 | "잘 동작하는지 어떻게 아나?" 질문 시 |
| autonomous vs semi-autonomous | 완전 자율 실행 vs 단계별 승인 — 조직 맥락에서의 선택 | human-in-the-loop를 깊이 논의할 때 |
| computer use / browser use | AI가 GUI를 직접 조작하는 새로운 형태의 tool use | tool calling 후 "화면도 조작할 수 있나?" 질문 시 |

### 심화 개념 진행 규칙

- 기본 개념이 모두 완료된 후에만 심화로 확장한다.
- 학습자가 관심을 보이거나 AI 경험이 높을 때 자연스럽게 도입한다.
- 심화 개념은 Phase 3 또는 Phase 4 이후 보너스로 다루되, 모듈 완료 기준에는 포함하지 않는다.
- 학습자가 원하지 않으면 넘어간다.

## 완료 기준

학습자가 다음을 설명하면 완료한다.

1. 챗봇이 일정 등록을 못 하는 이유 (도구/권한 부재)
2. Agent가 위험해질 수 있는 지점 1가지와 완화 방식

## 다음 연결

모듈 완료 시 다음 선택지를 `AskUserQuestion` 도구로 제시한다.

- 실제 도구 선택과 생태계 이해는 `module5-tools-ecosystem`
