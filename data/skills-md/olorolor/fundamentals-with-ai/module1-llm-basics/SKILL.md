---
name: module1-llm-basics
description: LLM의 본질(확률적 토큰 예측), hallucination의 구조적 원인, temperature의 의미를 학습시키는 모듈.
---

# Module 1: LLM Basics

핵심 질문: LLM은 정확히 무엇을 하는가?

## 학습 목표

- LLM을 "확률적 다음 토큰 예측기"로 설명할 수 있다.
- hallucination을 버그가 아니라 구조적 특성으로 설명할 수 있다.
- temperature 조절이 출력 특성에 미치는 영향을 설명할 수 있다.

## 진행 구조 (4단계, 목표 10~15분)

이 모듈은 반드시 아래 4단계를 순서대로 진행한다. 단계를 건너뛰지 않는다.

### Phase 1: 문제 도입 (2~3분, 최소 1회 학습자 응답 필요)

- 학습자의 직무 맥락에서 "같은 질문에 다른 답이 나오는" 경험을 끌어낸다.
- 정의나 용어 설명을 하지 않는다. 오직 경험과 현상에 대해서만 이야기한다.
- 학습자에게 경험을 묻는 질문으로 시작하고, 응답을 받은 후에야 Phase 2로 진행한다.

### Phase 2: 핵심 개념 탐구 (5~7분, 최소 3회 학습자 응답 필요)

아래 개념을 순서대로 다룬다. **한 응답에서 2개 이상의 새로운 개념을 동시에 설명하지 않는다.**

1. **확률적 생성** — LLM이 "다음 단어를 확률로 고른다"는 핵심 원리
2. **token** — 문자/단어가 아닌 토큰이 기본 단위라는 점
3. **hallucination** — 확률적 생성의 구조적 결과로서의 환각

각 개념마다:
- 직무 맥락 비유를 1개 이상 사용한다.
- 설명 후 반드시 학습자에게 확인 질문을 던지고 **응답을 기다린다**.
- 학습자가 응답한 후에야 다음 개념으로 넘어간다.
- 수사적 질문("~하죠?")을 던지고 바로 답을 주는 패턴을 금지한다.

### Phase 3: 연결 및 적용 (2~3분, 최소 1회 학습자 응답 필요)

- **temperature**를 도입하고, 앞에서 배운 확률적 생성/hallucination과의 관계를 학습자가 추론하게 한다.
- 직무 상황 시나리오 1개를 제시하여 "temperature를 높이면/낮추면 어떻게 될까?" 판단을 요청한다.
- 학습자의 응답을 받은 후에야 Phase 4로 진행한다.

### Phase 4: 이해 확인 (2~3분, 최소 1회 학습자 응답 필요)

완료 기준 질문을 제시한다. 학습자가 **자신의 언어로** 답해야 한다.

1. 같은 질문에 답이 달라질 수 있는 이유
2. hallucination이 발생하는 근본 이유

- 학습자의 답이 부족하면 Phase 2~3의 관련 부분으로 돌아가 보충한다.
- 충분하면 모듈 완료를 선언하고 다음 모듈을 안내한다.

## 페이스 규칙 (필수)

- **한 응답에서 2개 이상의 새로운 개념을 동시에 설명하지 않는다.**
- **학습자가 응답하지 않은 상태에서 다음 개념으로 넘어가지 않는다.**
- **최소 교환 횟수: AI 6회 응답 + 학습자 6회 응답 = 12턴 이상이어야 모듈 완료 가능.**
- 12턴 미만에서 완료 기준을 충족하더라도, 추가 연결 질문이나 적용 시나리오로 깊이를 확보한다.
- 선택지가 필요한 분기점에서는 `AskUserQuestion` 도구를 사용한다.

## 개념 체계 (기본 → 심화)

### 기본 (반드시 다룸)

| 개념 | 핵심 한 줄 | Phase |
|---|---|---|
| 확률적 생성 (next-token prediction) | LLM은 "다음에 올 확률이 높은 토큰"을 고르는 기계 | 2 |
| token | 문자/단어가 아닌, LLM이 처리하는 기본 단위 | 2 |
| hallucination | 확률적 생성의 구조적 결과 — 모르는 것도 그럴듯하게 만들어냄 | 2 |
| temperature | 확률 분포의 뾰족함/평탄함을 조절하여 일관성↔창의성 트레이드오프 결정 | 3 |

### 심화 (학습자가 관심을 보이거나, 경험 수준이 높을 때 확장)

| 개념 | 핵심 한 줄 | 언제 다루나 |
|---|---|---|
| top-k / top-p (nucleus sampling) | temperature 외에 출력을 제어하는 추가 파라미터 | temperature를 잘 이해한 후 |
| prompt engineering 기초 | system prompt, few-shot, zero-shot의 차이와 효과 | 확률적 생성을 이해한 후 |
| 모델 크기와 성능 관계 | 파라미터 수(7B, 70B, 405B)가 능력에 미치는 영향과 한계 | hallucination 논의 중 "더 큰 모델이면 안 생기나?" 질문 시 |
| inference 비용 구조 | 입력/출력 토큰 수 → 비용 계산 원리, 모델별 가격 차이 | token 개념 이해 후 비용에 관심을 보일 때 |
| open-source vs closed-source | Llama, Mistral vs GPT, Claude — 선택 기준과 트레이드오프 | 모델 비교에 관심을 보일 때 |
| multimodal | 텍스트 외 이미지/음성/영상을 처리하는 확장 | "텍스트만 되나요?" 질문 시 |

### 심화 개념 진행 규칙

- 기본 개념이 모두 완료된 후에만 심화로 확장한다.
- 학습자가 관심을 보이거나 AI 경험이 높을 때 자연스럽게 도입한다.
- 심화 개념은 Phase 3 또는 Phase 4 이후 보너스로 다루되, 모듈 완료 기준에는 포함하지 않는다.
- 학습자가 원하지 않으면 넘어간다.

## 완료 기준

학습자가 다음 2가지를 자신의 언어로 답하면 완료한다.

1. 같은 질문에 답이 달라질 수 있는 이유
2. hallucination이 발생하는 근본 이유

## 다음 연결

모듈 완료 시 다음 선택지를 `AskUserQuestion` 도구로 제시한다.

- 문서 길이 한계와 맥락 관리가 궁금하면 `module2-tokens-context`
