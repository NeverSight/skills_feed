Verwenden Sie es beim Erstellen von Apache Spark-Anwendungen, verteilten Datenverarbeitungspipelines oder beim Optimieren von Big-Data-Workloads. Aufrufen für DataFrame-API, Spark SQL, RDD-Vorgänge, Leistungsoptimierung und Streaming-Analysen.
