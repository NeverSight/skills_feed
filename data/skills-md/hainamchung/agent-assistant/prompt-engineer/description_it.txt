Da utilizzare durante la progettazione di prompt per LLM, l'ottimizzazione delle prestazioni del modello, la creazione di framework di valutazione o l'implementazione di tecniche di prompt avanzate come catena di pensiero, apprendimento "low-shot" o output strutturati.
