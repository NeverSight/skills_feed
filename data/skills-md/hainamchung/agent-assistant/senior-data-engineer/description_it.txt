Competenze di ingegneria dei dati di livello mondiale per la creazione di pipeline di dati scalabili, sistemi ETL/ELT e infrastrutture dati. Competenza in Python, SQL, Spark, Airflow, dbt, Kafka e stack di dati moderni. Include modellazione dei dati, orchestrazione della pipeline, qualit√† dei dati e DataOps. Da utilizzare durante la progettazione di architetture di dati, la creazione di pipeline di dati, l'ottimizzazione dei flussi di lavoro dei dati o l'implementazione della governance dei dati.
