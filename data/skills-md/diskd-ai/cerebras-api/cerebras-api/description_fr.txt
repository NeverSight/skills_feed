Intégration de l'API Cerebras pour créer des applications basées sur l'IA avec une inférence LLM ultra-rapide. À utiliser lorsque vous travaillez avec l'API Chat Completions de Cerebras, le SDK Python (cerebras_cloud_sdk), le SDK TypeScript (@cerebras/cerebras_cloud_sdk), l'utilisation d'outils/appels de fonctions, les sorties structurées avec des schémas JSON, les modèles de raisonnement avec des jetons de réflexion, les réponses en continu ou toute tâche d'intégration de l'API Cerebras. Se déclenche sur les mentions de Cerebras, Cerebras Inference, Llama on Cerebras, Qwen on Cerebras, GLM ou besoins d'inférence rapide LLM.
