Esta habilidad debe usarse cuando los usuarios quieran entrenar o perfeccionar modelos de lenguaje utilizando TRL (Transformer Reinforcement Learning) en la infraestructura de Hugging Face Jobs. Cubre SFT, DPO, GRPO y métodos de capacitación de modelado de recompensas, además de la conversión de GGUF para implementación local. Incluye orientación sobre el paquete TRL Jobs, scripts UV con formato PEP 723, preparación y validación de conjuntos de datos, selección de hardware, estimación de costos, monitoreo de Trackio, autenticación de Hub y persistencia de modelos. Debe invocarse para tareas que involucran entrenamiento de GPU en la nube, conversión de GGUF o cuando los usuarios mencionan entrenamiento en Hugging Face Jobs sin configuración de GPU local.
