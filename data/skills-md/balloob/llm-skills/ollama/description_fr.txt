Utilisez-le si l'utilisateur souhaite se connecter à Ollama ou exploiter Ollama sous n'importe quelle forme dans son projet. Guidez les utilisateurs qui intègrent Ollama dans leurs projets pour l’inférence d’IA locale. Couvre l'installation, la configuration de la connexion, la gestion des modèles et l'utilisation de l'API pour Python et Node.js. Aide à la génération de texte, aux interfaces de discussion, aux intégrations, aux réponses en continu et à la création d'applications basées sur l'IA à l'aide de LLM locaux.
