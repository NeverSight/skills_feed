Erstellen, validieren und implementieren Sie LLM-as-Judge-Evaluatoren für die automatisierte Qualitätsbewertung der LLM-Pipeline-Ergebnisse. Verwenden Sie diese Fertigkeit, wann immer der Benutzer einen automatisierten Bewerter für subjektive oder nuancierte Fehlermodi erstellen möchte, eine Aufforderung zur Gut/Schlecht-Beurteilung verfassen, beschriftete Daten für die Gutachterentwicklung aufteilen, die Richterausrichtung (TPR/TNR) messen, echte Erfolgsraten mit Bias-Korrektur schätzen oder CI-Bewertungspipelines einrichten möchte. Wird auch ausgelöst, wenn der Benutzer „Beurteilungsaufforderung“, „automatisierte Bewertung“, „LLM-Bewerter“, „Bewertungsaufforderung“, „Ausrichtungsmetriken“, „True-Positive-Rate“ erwähnt oder von der manuellen Trace-Überprüfung zur automatisierten Bewertung wechseln möchte. Diese Fähigkeit deckt den gesamten Lebenszyklus ab: Prompt-Design → Datenaufteilung → iterative Verfeinerung → Erfolgsratenschätzung.
