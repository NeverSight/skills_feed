Методология LLM как судьи для сравнения реализаций кода в разных репозиториях. Оценивает реализации по функциональности, безопасности, качеству тестирования, чрезмерному проектированию и мертвому коду с использованием взвешенных критериев. Используется командой /beagle:llm-judge.
