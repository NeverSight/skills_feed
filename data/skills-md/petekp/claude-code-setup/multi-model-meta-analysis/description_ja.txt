複数の AI モデルからの出力を統合して、包括的な検証済みの評価を作成します。次の場合に使用します: (1) ユーザーがコードまたはプロジェクトに関する複数の LLM (Claude、GPT、Gemini など) からのフィードバック/分析を貼り付ける、(2) ユーザーがモデルの出力を単一の信頼できるドキュメントに統合したい、(3) ユーザーが実際のソース コードに対して競合するモデルの主張を解決する必要がある。このスキルは、コードベースに対してモデルの主張を検証し、証拠を使って矛盾を解決し、単一のモデルよりも信頼性の高い評価を生成します。
