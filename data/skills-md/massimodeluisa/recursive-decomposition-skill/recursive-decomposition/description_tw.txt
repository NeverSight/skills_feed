基於Zhang、Kraska 和 Khattab (2025) 的遞歸語言模型 (RLM) 研究，該技能提供了通過編程分解和遞歸自調用來處理超出舒適上下文限制的任務的策略。觸發諸如“分析所有文件”、“處理這個大文檔”、“聚合信息”、“跨代碼庫搜索”或涉及 10 個以上文件或 50k 以上標記的任務等短語。
