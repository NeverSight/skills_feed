Basierend auf der Recursive Language Models (RLM)-Forschung von Zhang, Kraska und Khattab (2025) bietet diese Fertigkeit Strategien für die Bewältigung von Aufgaben, die komfortable Kontextgrenzen überschreiten, durch programmatische Zerlegung und rekursiven Selbstaufruf. Wird bei Ausdrücken wie „Alle Dateien analysieren“, „Dieses große Dokument verarbeiten“, „Informationen aggregieren aus“, „in der gesamten Codebasis suchen“ oder bei Aufgaben mit mehr als 10 Dateien oder mehr als 50.000 Token ausgelöst.
