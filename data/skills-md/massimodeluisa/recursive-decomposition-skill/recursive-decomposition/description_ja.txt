Zhang、Kraska、Khattab (2025) による再帰言語モデル (RLM) 研究に基づいたこのスキルは、プログラムによる分解と再帰的自己呼び出しを通じて、快適なコンテキストの制限を超えるタスクを処理するための戦略を提供します。 「すべてのファイルを分析する」、「この大きなドキュメントを処理する」、「情報を集約する」、「コードベース全体を検索する」などのフレーズ、または 10 個以上のファイルまたは 50,000 個以上のトークンを含むタスクでトリガーされます。
