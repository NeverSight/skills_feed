Evaluate agent task outputs using a three-dimension rubric (Semantic, Pragmatic, Syntactic) derived from the KLS quality framework. Use when: (1) a task has been completed and needs quality assessment before acceptance, (2) automated post-task quality checks are required, (3) multi-model consensus verdicts are needed for agent outputs, (4) documentation, code, or specification quality must be scored with structured JSON verdicts, or (5) a human fallback decision is needed after model disagreement. Produces JSONL verdict records compatible with the verdict schema in automation/judge/.
