Exécutez du code Python dans le cloud avec des conteneurs sans serveur, des GPU et une mise à l'échelle automatique. À utiliser lors du déploiement de modèles ML, de l'exécution de tâches par lots, de la planification de tâches, de la diffusion d'API avec accélération GPU ou de la mise à l'échelle de charges de travail gourmandes en calcul. Se déclenche sur les demandes d'infrastructure GPU sans serveur, d'inférence LLM, de formation/réglage de modèles, de traitement de données parallèle, de tâches cron dans le cloud ou de déploiement de points de terminaison Web Python.
