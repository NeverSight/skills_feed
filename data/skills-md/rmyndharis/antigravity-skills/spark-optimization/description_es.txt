Optimice los trabajos de Apache Spark con partición, almacenamiento en caché, optimización aleatoria y ajuste de memoria. Úselo para mejorar el rendimiento de Spark, depurar trabajos lentos o escalar canalizaciones de procesamiento de datos.
