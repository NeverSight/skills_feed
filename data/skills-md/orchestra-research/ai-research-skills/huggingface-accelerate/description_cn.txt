最简单的分布式训练 API。 4 行即可为任何 PyTorch 脚本添加分布式支持。 DeepSpeed/FSDP/Megatron/DDP 的统一 API。自动器件贴装，混合精度（FP16/BF16/FP8）。交互式配置，单一启动命令。 HuggingFace 生态系统标准。
