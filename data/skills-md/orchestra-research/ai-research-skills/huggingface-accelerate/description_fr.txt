API de formation distribuée la plus simple. 4 lignes pour ajouter un support distribué à n'importe quel script PyTorch. API unifiée pour DeepSpeed/FSDP/Megatron/DDP. Placement automatique des appareils, précision mixte (FP16/BF16/FP8). Configuration interactive, commande de lancement unique. Norme de l’écosystème HuggingFace.
