Fournit une pré-formation LLM distribuée native de PyTorch à l'aide de torchtitan avec parallélisme 4D (FSDP2, TP, PP, CP). À utiliser lors du pré-entraînement de Llama 3.1, DeepSeek V3 ou de modèles personnalisés à l'échelle de 8 à plus de 512 GPU avec Float8, torch.compile et les points de contrôle distribués.
