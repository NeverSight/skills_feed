使用 NVIDIA TensorRT 優化 LLM 推理，以實現最大吞吐量和最低延遲。當您需要比 PyTorch 快 10-100 倍的推理速度時，可用於 NVIDIA GPU (A100/H100) 上的生產部署，或用於透過量化 (FP8/INT4)、動態批次和多 GPU 擴充功能來服務模型。
