최대 처리량과 최저 대기 시간을 위해 NVIDIA TensorRT로 LLM 추론을 최적화합니다. PyTorch보다 10~100배 더 빠른 추론이 필요한 경우 NVIDIA GPU(A100/H100)의 프로덕션 배포에 사용하거나 양자화(FP8/INT4), 진행 중 일괄 처리 및 다중 GPU 확장을 통해 모델을 제공하는 데 사용하세요.
