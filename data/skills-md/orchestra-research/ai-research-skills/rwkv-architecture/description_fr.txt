Hybride RNN+Transformer avec inférence O(n). Temps linéaire, contexte infini, pas de cache KV. Entraînez-vous comme GPT (parallèle), déduisez comme RNN (séquentiel). Projet d'IA de la Fondation Linux. Production chez Windows, Office, NeMo. RWKV-7 (mars 2025). Modèles jusqu'à 14B paramètres.
