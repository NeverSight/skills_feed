RNN+Transformer-Hybrid mit O(n)-Inferenz. Lineare Zeit, unendlicher Kontext, kein KV-Cache. Trainieren Sie wie GPT (parallel), schließen Sie wie RNN (sequentiell). KI-Projekt der Linux Foundation. Produktion unter Windows, Office, NeMo. RWKV-7 (März 2025). Modelle mit bis zu 14B Parametern.
