Tokenizers rapides optimisés pour la recherche et la production. L’implémentation basée sur Rust tokenise 1 Go en <20 secondes. Prend en charge les algorithmes BPE, WordPièce et Unigram. Entraînez des vocabulaires personnalisés, suivez les alignements, gérez le remplissage/troncature. S'intègre parfaitement aux transformateurs. À utiliser lorsque vous avez besoin d'une tokenisation hautes performances ou d'une formation sur la tokenisation personnalisée.
