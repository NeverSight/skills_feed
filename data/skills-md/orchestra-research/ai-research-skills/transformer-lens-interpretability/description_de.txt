Bietet Anleitungen für die mechanistische Interpretierbarkeitsforschung mit TransformerLens, um Transformator-Interna über HookPoints und Aktivierungs-Caching zu überprüfen und zu manipulieren. Verwenden Sie es, wenn Sie Modellalgorithmen zurückentwickeln, Aufmerksamkeitsmuster untersuchen oder Aktivierungs-Patching-Experimente durchführen.
