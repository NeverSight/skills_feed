Ottimizzazione efficiente dei parametri per LLM utilizzando i metodi LoRA, QLoRA e oltre 25. Da utilizzare durante la regolazione fine di modelli di grandi dimensioni (7B-70B) con memoria GPU limitata, quando è necessario addestrare <1% dei parametri con una perdita di precisione minima o per la fornitura di più adattatori. La libreria ufficiale di HuggingFace integrata con l'ecosistema dei trasformatori.
