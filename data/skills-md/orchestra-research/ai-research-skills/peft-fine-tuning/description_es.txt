Ajuste eficiente de parámetros para LLM que utilizan métodos LoRA, QLoRA y más de 25. Úselo cuando ajuste modelos grandes (7B-70B) con memoria de GPU limitada, cuando necesite entrenar <1% de los parámetros con una pérdida de precisión mínima o para servicio de múltiples adaptadores. Biblioteca oficial de HuggingFace integrada con el ecosistema de transformadores.
