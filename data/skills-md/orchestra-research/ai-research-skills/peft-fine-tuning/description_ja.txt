LoRA、QLoRA、および 25 以上のメソッドを使用した LLM のパラメータ効率の高い微調整。限られた GPU メモリで大規模なモデル (7B ～ 70B) を微調整する場合、精度損失を最小限に抑えて 1% 未満のパラメータをトレーニングする必要がある場合、またはマルチアダプターのサービスを行う場合に使用します。 HuggingFace の公式ライブラリはトランスフォーマーのエコシステムと統合されています。
