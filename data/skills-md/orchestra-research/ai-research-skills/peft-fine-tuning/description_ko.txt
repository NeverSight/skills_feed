LoRA, QLoRA 및 25개 이상의 방법을 사용하여 LLM에 대한 매개변수 효율적인 미세 조정. GPU 메모리가 제한된 대규모 모델(7B-70B)을 미세 조정할 때, 정확도 손실을 최소화하면서 1% 미만의 매개변수를 학습해야 할 때 또는 다중 어댑터 제공에 사용하세요. HuggingFace의 공식 라이브러리는 Transformers 생태계와 통합되어 있습니다.
