使用 LoRA、QLoRA 和 25 種以上方法對 LLM 進行參數高效的微調。當使用有限的 GPU 記憶體微調大型模型 (7B-70B)、需要以最小的精度損失訓練 <1% 的參數或用於多適配器服務時，請使用。 HuggingFace 的官方庫與 Transformer 生態系統整合。
