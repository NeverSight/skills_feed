使用 LoRA、QLoRA 和 25 种以上方法对 LLM 进行参数高效的微调。当使用有限的 GPU 内存微调大型模型 (7B-70B)、需要以最小的精度损失训练 <1% 的参数或用于多适配器服务时，请使用。 HuggingFace 的官方库与 Transformer 生态系统集成。
