Ajustement précis des paramètres pour les LLM à l'aide des méthodes LoRA, QLoRA et plus de 25. À utiliser lors du réglage fin de grands modèles (7B-70B) avec une mémoire GPU limitée, lorsque vous devez entraîner <1 % des paramètres avec une perte de précision minimale, ou pour le service multi-adaptateurs. La bibliothèque officielle de HuggingFace intégrée à l'écosystème des transformateurs.
