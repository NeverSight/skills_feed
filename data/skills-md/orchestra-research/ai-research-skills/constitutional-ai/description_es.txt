El método de Anthropic para entrenar IA inofensiva mediante la superación personal. Enfoque de dos fases: aprendizaje supervisado con autocrítica/revisión, luego RLAIF (RL de AI Feedback). Úselo para alineación de seguridad, reduciendo resultados dañinos sin etiquetas humanas. Alimenta el sistema de seguridad de Claude.
