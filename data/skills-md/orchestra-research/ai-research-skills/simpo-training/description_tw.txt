LLM 對齊的簡單偏好優化。 DPO 的無參考替代方案，具有更好的性能（在 AlpacaEval 2.0 上+6.4 分）。無需參考模型，比DPO更有效率。當需要比 DPO/PPO 更簡單、更快的訓練時，可用於偏好調整。
