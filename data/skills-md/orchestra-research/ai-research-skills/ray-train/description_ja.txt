クラスター全体にわたる分散トレーニング オーケストレーション。 PyTorch/TensorFlow/HuggingFace をラップトップから数千のノードに拡張します。 Ray Tune による組み込みのハイパーパラメータ調整、フォールト トレランス、エラスティック スケーリング。複数のマシンにわたって大規模なモデルをトレーニングする場合、または分散ハイパーパラメーター スイープを実行する場合に使用します。
