Обслуживает LLM с высокой пропускной способностью, используя PagedAttention vLLM и непрерывную пакетную обработку. Используйте при развертывании производственных API-интерфейсов LLM, оптимизации задержки/пропускной способности вывода или обслуживания моделей с ограниченной памятью графического процессора. Поддерживает OpenAI-совместимые конечные точки, квантование (GPTQ/AWQ/FP8) и тензорный параллелизм.
