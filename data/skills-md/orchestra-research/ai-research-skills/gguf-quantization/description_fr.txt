Format GGUF et quantification llama.cpp pour une inférence CPU/GPU efficace. À utiliser lors du déploiement de modèles sur du matériel grand public, Apple Silicon, ou lorsque vous avez besoin d'une quantification flexible de 2 à 8 bits sans exigences GPU.
