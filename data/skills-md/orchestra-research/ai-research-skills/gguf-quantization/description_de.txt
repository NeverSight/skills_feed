GGUF-Format und llama.cpp-Quantisierung für effiziente CPU/GPU-Inferenz. Verwenden Sie diese Option, wenn Sie Modelle auf Consumer-Hardware oder Apple Silicon bereitstellen oder wenn Sie eine flexible Quantisierung von 2 bis 8 Bit ohne GPU-Anforderungen benötigen.
