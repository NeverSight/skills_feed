Formato GGUF e quantizzazione llama.cpp per un'efficiente inferenza CPU/GPU. Da utilizzare quando si distribuiscono modelli su hardware consumer, Apple Silicon o quando Ã¨ necessaria una quantizzazione flessibile da 2 a 8 bit senza requisiti GPU.
