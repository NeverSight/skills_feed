GGUF 形式と llama.cpp 量子化による効率的な CPU/GPU 推論。消費者向けハードウェアや Apple Silicon にモデルをデプロイする場合、または GPU を必要とせずに 2 ～ 8 ビットの柔軟な量子化が必要な場合に使用します。
