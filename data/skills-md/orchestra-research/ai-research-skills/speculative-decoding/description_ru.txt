Ускорьте вывод LLM, используя спекулятивное декодирование, множественные головки Medusa и методы упреждающего декодирования. Используйте при оптимизации скорости вывода (ускорение в 1,5–3,6 раза), уменьшении задержки для приложений реального времени или при развертывании моделей с ограниченными вычислительными ресурсами. Охватывает черновые модели, древовидную структуру, итерацию Якоби, параллельную генерацию токенов и стратегии производственного развертывания.
