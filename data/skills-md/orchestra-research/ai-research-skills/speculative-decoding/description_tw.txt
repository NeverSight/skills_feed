使用推測性解碼、Medusa 多頭和前瞻解碼技術加速 LLM 推理。在優化推理速度（1.5-3.6 倍加速）、減少即時應用程式的延遲或部署計算有限的模型時使用。涵蓋草稿模型、基於樹的注意力、雅可比迭代、平行令牌產生和生產部署策略。
