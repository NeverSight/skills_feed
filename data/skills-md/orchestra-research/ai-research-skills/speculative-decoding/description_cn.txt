使用推测性解码、Medusa 多头和前瞻解码技术加速 LLM 推理。在优化推理速度（1.5-3.6 倍加速）、减少实时应用程序的延迟或部署计算有限的模型时使用。涵盖草稿模型、基于树的注意力、雅可比迭代、并行令牌生成和生产部署策略。
