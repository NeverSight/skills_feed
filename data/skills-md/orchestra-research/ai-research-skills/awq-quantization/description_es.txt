Cuantización de peso consciente de la activación para compresión LLM de 4 bits con aceleración 3x y pérdida mínima de precisión. Úselo cuando implemente modelos grandes (7B-70B) en memoria de GPU limitada, cuando necesite una inferencia más rápida que GPTQ con una mejor preservación de la precisión, o para modelos multimodales y ajustados por instrucciones. Ganador del premio al mejor artículo MLSys 2024.
