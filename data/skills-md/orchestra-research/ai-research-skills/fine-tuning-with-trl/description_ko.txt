TRL(명령 조정을 위한 SFT, 선호도 정렬을 위한 DPO, 보상 최적화를 위한 PPO/GRPO, 보상 모델 훈련)을 통한 강화 학습을 사용하여 LLM을 미세 조정합니다. RLHF가 필요할 때 사용하고, 선호도에 따라 모델을 정렬하거나, 사람의 피드백을 바탕으로 훈련하세요. HuggingFace Transformers와 함께 작동합니다.
