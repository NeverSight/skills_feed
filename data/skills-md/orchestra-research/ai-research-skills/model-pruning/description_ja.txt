Wanda や SparseGPT などの枝刈り手法を使用して、LLM サイズを削減し、推論を高速化します。再トレーニングせずにモデルを圧縮する場合、精度損失を最小限に抑えて 50% のスパース性を達成する場合、またはハードウェア アクセラレータでのより高速な推論を可能にする場合に使用します。非構造化プルーニング、構造化プルーニング、N:M スパース性、マグニチュード プルーニング、およびワンショット手法をカバーします。
