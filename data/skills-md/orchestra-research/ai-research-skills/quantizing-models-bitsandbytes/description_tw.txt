將 LLM 量化為 8 位或 4 位，可減少 50-75% 的內存，同時將精度損失降至最低。當 GPU 記憶體有限、需要適應更大的模型或想要更快的推理時使用。支援 INT8、NF4、FP4 格式、QLoRA 訓練和 8 位元優化器。與 HuggingFace 變形金剛一起使用。
