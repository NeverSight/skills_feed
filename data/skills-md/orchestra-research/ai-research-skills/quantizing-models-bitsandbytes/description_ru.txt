Квантует LLM до 8-битных или 4-битных для сокращения памяти на 50-75% с минимальной потерей точности. Используйте, когда память графического процессора ограничена, необходимо использовать более крупные модели или требуется более быстрый вывод. Поддерживает форматы INT8, NF4, FP4, обучение QLoRA и 8-битные оптимизаторы. Работает с трансформерами HuggingFace.
