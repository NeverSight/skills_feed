RAG/LLM 접지에 사용합니다. LLM에 최적화된 사전 추출된 웹 콘텐츠(텍스트, 표, 코드)를 반환합니다. GET + POST. 복잡성에 따라 max_tokens/count를 조정합니다. 고글, 로컬/POI를 지원합니다. AI 답변의 경우 답변을 사용하세요. AI/에이전트 애플리케이션을 구축하는 모든 사람에게 권장됩니다.
