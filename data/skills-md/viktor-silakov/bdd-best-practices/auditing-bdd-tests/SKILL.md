---
name: auditing-bdd-tests
description: Analyzes BDD (Gherkin) + Playwright test solutions for spec quality, flake resistance, semantic/a11y locators, and AI-agent operability. Produces aspect scoring, grade, issues by severity, and improvement roadmap.
user-invocable: true
argument-hint: [path-to-repo]
---

# BDD Test Solution Audit

Goal: evaluate **specification executability**, **flake resistance**, **maintainability**, **semantic/a11y quality**, and **AI-agent operability**.

## Adaptive Workflow

Workflow adapts based on repository size (auto-detected).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. DISCOVER â†’ 2. ANALYZE â†’ 3. SCORE â†’ 4. REPORT â†’ 5. ROADMAP   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†‘                                                      â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Skip steps for small repos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Repo Size | Steps | Sampling | Questions |
|-----------|-------|----------|-----------|
| Small (â‰¤20 scenarios) | 1â†’3â†’4 | None | 1 question |
| Medium (21â€“100) | 1â†’2â†’3â†’4â†’5 | 30â€“50% | 2 questions |
| Large (100+) | Full | Stratified | 3 questions |

---

## Step 1: Discovery & Auto-Inference

Target: `{argument OR cwd}`

**Auto-detect (no user input needed):**

| What | How to Detect |
|------|---------------|
| Stack | `playwright.config.*` â†’ Playwright; `playwright-bdd` in package.json â†’ playwright-bdd |
| Size | Count `*.feature` files and `Scenario:` lines |
| History | Check `.bddready/history/index.json` exists |
| CI | Check `.github/workflows/`, `Jenkinsfile`, `.gitlab-ci.yml` |
| Artifacts | Check `playwright.config.*` for trace/video/screenshot settings |

**Output immediately:**
```
Target: {path}
Stack: {stack} (auto-detected)
Size: {small/medium/large} ({N} features, {M} scenarios)
History: {yes/no} | CI: {yes/no} | Artifacts: {configured/missing}
```

See `modules/discovery.md` for detailed detection rules.

---

## Step 2: Sampling (Medium/Large repos only)

Skip for small repos â€” analyze all scenarios.

For medium/large repos, use stratified sampling. See `modules/sampling.md`.

---

## Progress Indicator (Medium/Large repos)

For repositories with 50+ scenarios, show progress during analysis:

```
Analyzing BDD Test Solution...
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0%

[â– â– â– â– â– â– â– â– â– â– â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 25%
âœ“ Discovery complete (playwright-bdd detected)
â†’ Analyzing features/auth/*.feature (8 scenarios)

[â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 50%
â†’ Analyzing features/checkout/*.feature (12 scenarios)

[â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 75%
â†’ Scoring aspects...

[â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– ] 100%
âœ“ Analysis complete
```

**Progress stages:**
1. Discovery (10%)
2. Feature file analysis (10-70%, proportional to file count)
3. Step definition analysis (70-85%)
4. Scoring (85-95%)
5. Report generation (95-100%)

Update progress after each feature file or major step.

---

## Step 3: Score Aspects

Score each aspect using rubrics from `criteria/aspects.md`.

**Aspects and weights:**

| # | Aspect | Weight |
|---|--------|--------|
| 1 | Executable Gherkin | 16% |
| 2 | Step Definitions Quality | 14% |
| 3 | Test Architecture | 14% |
| 4 | Selector Strategy | 12% |
| 5 | Waiting & Flake Resistance | 14% |
| 6 | Data & Environment | 10% |
| 7 | CI, Reporting & Artifacts | 10% |
| 8 | AI-Agent Operability | 10% |

**Scoring:** 0 (bad) / 5 (partial) / 10 (good) per criterion.

See `modules/scoring.md` for calculation formulas.

---

## Step 4: Report

### 4.1 Terminal Output (Always)

Print ASCII dashboard with scores and issues. See `modules/output-formats.md`.

### 4.2 Issues by Severity

Classify using `reference/severity.md`:
- ğŸ”´ **CRITICAL** â€” blocks reliable execution
- ğŸŸ¡ **WARNING** â€” hinders speed/maintainability  
- ğŸ”µ **INFO** â€” optimizations

**Every issue MUST have:**
- Evidence (file path, pattern, or code snippet)
- Impact (why it matters)
- Effort estimate (Low/Medium/High)

### 4.3 Save Reports

Save to `.bddready/history/reports/`:
- `{REPORT_ID}.json` â€” machine-readable
- `{REPORT_ID}.md` â€” human-readable

Update `.bddready/history/index.json` for delta tracking.

### 4.4 HTML Report (Offer to User)

After showing terminal output, ask:

> Would you like me to generate an interactive HTML report?

If yes, run:
```bash
node scripts/render-html.mjs .bddready/history/reports/{REPORT_ID}.json .bddready/history/reports/{REPORT_ID}.html
```

---

## Interactive Fix Mode

After showing issues, offer to fix quick wins immediately.

### Trigger Conditions

Offer interactive fixes when:
- At least 1 CRITICAL issue with `Effort: Low`
- Issue has clear, automatable fix pattern

### Flow

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     QUICK FIX AVAILABLE                          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  [C1] Flake Resistance: Found 7 arbitrary sleeps                 â•‘
â•‘       Fix: Replace `wait X seconds` with condition waits         â•‘
â•‘       Effort: Low | Files: 3                                     â•‘
â•‘                                                                  â•‘
â•‘  â†’ Fix C1 now? [y/n/skip all]                                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Response Handling

| Response | Action |
|----------|--------|
| `y` / `yes` | Apply fix, show diff, continue to next fixable issue |
| `n` / `no` | Skip this issue, continue to next |
| `skip all` / `s` | Skip interactive mode, show full report |

### Fixable Patterns

| Issue Pattern | Auto-Fix |
|---------------|----------|
| `wait X seconds` without condition | â†’ `waitFor` with visibility/enabled check |
| Hardcoded `sleep()` | â†’ `waitForSelector()` or `waitForResponse()` |
| CSS class selectors | â†’ `getByRole()` / `getByTestId()` (suggest, confirm) |
| Missing `trace: 'on-first-retry'` | â†’ Add to playwright.config |
| Duplicate step definitions | â†’ Consolidate (show which to keep) |

### After Each Fix

```
âœ“ Fixed C1: Replaced 7 sleeps with condition waits
  Modified: features/checkout.feature, features/auth.feature
  
â†’ Fix C2 now? [y/n/skip all]
```

### Post-Fix Summary

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     FIX SUMMARY                                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  âœ“ C1: Fixed (7 sleeps â†’ condition waits)                        â•‘
â•‘  âœ“ C3: Fixed (added trace-on-failure)                            â•‘
â•‘  âœ— C2: Skipped (requires manual review)                          â•‘
â•‘                                                                  â•‘
â•‘  Files modified: 5                                               â•‘
â•‘  New score estimate: 68 â†’ 74 (+6)                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Step 5: Roadmap (Medium/Large repos only)

Skip for small repos â€” provide inline recommendations instead.

| Phase | Focus |
|-------|-------|
| 1: Quick Wins | Remove sleeps, enable trace-on-failure, fix critical selectors |
| 2: Foundation | Thin step defs, proper fixtures, test isolation |
| 3: Advanced | Visual tests, a11y integration, CI optimization |

---

## User Questions

### Auto-Inference First

Before asking, try to infer from codebase:

| Question | Auto-Inference |
|----------|----------------|
| Primary goal? | Infer from issues: many sleeps â†’ stability; bad selectors â†’ AI-ready |
| Depth of changes? | Infer from repo size: small â†’ quick wins; large â†’ phased |
| CI constraints? | Read from config: worker count, timeout settings |

### Minimal Question Set

Ask ONLY what cannot be inferred:

**Small repos (1 question):**
> What is your priority: stability, speed, or AI-agent readability?

**Medium repos (2 questions):**
1. What is your priority: stability, speed, or AI-agent readability?
2. How deep can changes go: quick fixes only, or can we refactor?

**Large repos (3 questions):**
1. What is your priority: stability, speed, or AI-agent readability?
2. How deep can changes go: quick fixes only, medium refactor, or deep restructuring?
3. Are there CI/environment constraints? (e.g., worker limits, no mocks, staging only)

### Dynamic Questions (Only if triggered)

Ask ONLY if specific issues found:

| Trigger | Question |
|---------|----------|
| CRITICAL issues found | Which CRITICAL items should be fixed first? (list by ID) |
| Selector/a11y issues | Can we modify application markup (HTML), or tests only? |
| >10 WARNING issues | Which WARNING items are in scope this iteration? |

---

## Semantic/A11y Refactoring Proposal

If Aspect 4 (Selector Strategy) or Aspect 8 (AI-Agent Operability) scores below 60, propose:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           SEMANTIC/A11Y REFACTORING PROPOSAL                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Your locators would be more stable with semantic HTML.          â•‘
â•‘                                                                  â•‘
â•‘  Would you like me to help refactor:                             â•‘
â•‘  [ ] Component markup (replace div onclick â†’ button, add ARIA)   â•‘
â•‘  [ ] Test locators (migrate CSS â†’ getByRole)                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

Ask only if user has access to modify application source code.

---

## Reference Files

| File | Purpose |
|------|---------|
| `criteria/aspects.md` | Detailed scoring rubrics (0/5/10) |
| `reference/severity.md` | Issue classification rules |
| `reference/bdd-best-practices.md` | Best practices guide |
| `modules/discovery.md` | Discovery details |
| `modules/sampling.md` | Sampling strategy |
| `modules/scoring.md` | Score calculation |
| `modules/output-formats.md` | Output format specs |
| `templates/report.html` | HTML report template |
| `scripts/render-html.mjs` | HTML generator script |

---

## Quick Reference: Workflow by Size

### Small Repo (â‰¤20 scenarios)
1. Discover (auto-detect stack, size)
2. Ask 1 question (priority)
3. Analyze all scenarios
4. Score aspects (simplified)
5. Print terminal report + issues
6. **Interactive fix mode** (if Low-effort CRITICAL issues)
7. Offer HTML report
8. Provide inline recommendations

### Medium Repo (21â€“100 scenarios)
1. Discover (auto-detect)
2. Ask 2 questions
3. Sample 30â€“50%
4. **Show progress** (50+ scenarios)
5. Full aspect scoring
6. Terminal + saved reports
7. **Interactive fix mode**
8. Offer HTML report
9. Phased roadmap (3 phases)

### Large Repo (100+ scenarios)
1. Discover (auto-detect)
2. Ask 3 questions
3. Stratified sampling
4. **Show progress** (with stage updates)
5. Full aspect scoring
6. All report formats
7. **Interactive fix mode**
8. HTML report
9. Detailed phased roadmap
10. Propose a11y refactoring if applicable
