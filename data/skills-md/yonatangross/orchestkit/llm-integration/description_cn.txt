用于函数调用、流响应、Ollama 本地推理以及微调定制的 LLM 集成模式。在实现工具使用、SSE 流、本地模型部署、LoRA/QLoRA 微调或多提供商 LLM API 时使用。
