Modèles d'intégration LLM pour l'appel de fonctions, les réponses en streaming, l'inférence locale avec Ollama et la personnalisation fine. À utiliser lors de la mise en œuvre de l'utilisation d'outils, du streaming SSE, du déploiement de modèles locaux, du réglage fin LoRA/QLoRA ou des API LLM multi-fournisseurs.
