Modelli di integrazione LLM per chiamate di funzioni, risposte in streaming, inferenza locale con Ollama e personalizzazione della messa a punto. Da utilizzare durante l'implementazione dell'uso degli strumenti, dello streaming SSE, della distribuzione del modello locale, della messa a punto di LoRA/QLoRA o delle API LLM multi-provider.
