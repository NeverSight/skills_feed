Inférence LLM hautes performances avec vLLM, quantification (AWQ, GPTQ, FP8), décodage spéculatif et déploiement périphérique. À utiliser pour optimiser la latence, le débit ou la mémoire d’inférence.
