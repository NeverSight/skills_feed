Hochleistungs-LLM-Inferenz mit vLLM, Quantisierung (AWQ, GPTQ, FP8), spekulativer Dekodierung und Edge-Bereitstellung. Zur Optimierung der Inferenzlatenz, des Durchsatzes oder des Speichers.
