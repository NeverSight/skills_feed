Modèles de sécurité pour les intégrations LLM, y compris la défense contre les injections rapides et la prévention des hallucinations. À utiliser lors de la mise en œuvre de la séparation de contexte, de la validation des sorties LLM ou de la protection contre les attaques par injection rapide.
