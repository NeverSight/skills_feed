La méthode d'Anthropic pour entraîner une IA inoffensive grâce à l'auto-amélioration. Approche en deux phases - apprentissage supervisé avec autocritique/révision, puis RLAIF (RL from AI Feedback). À utiliser pour l'alignement de sécurité, réduisant les sorties nocives sans étiquettes humaines. Alimente le système de sécurité de Claude.
