使用 NVIDIA TensorRT 優化 LLM 推理，以實現最大吞吐量和最低延遲。當您需要比 PyTorch 快 10-100 倍的推理速度時，可用於 NVIDIA GPU (A100/H100) 上的生產部署，或者用於通過量化 (FP8/INT4)、動態批處理和多 GPU 擴展來服務模型。
