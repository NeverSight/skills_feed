NVIDIA TensorRT を使用して LLM 推論を最適化し、最大のスループットと最小のレイテンシを実現します。 PyTorch よりも 10 ～ 100 倍高速な推論が必要な場合、または量子化 (FP8/INT4)、インフライト バッチ処理、およびマルチ GPU スケーリングを使用したモデルの提供に使用する場合、NVIDIA GPU (A100/H100) での運用環境のデプロイメントに使用します。
