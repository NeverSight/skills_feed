Оптимизирует вывод LLM с помощью NVIDIA TensorRT для максимальной пропускной способности и минимальной задержки. Используйте для производственного развертывания на графических процессорах NVIDIA (A100/H100), когда вам требуется в 10–100 раз более быстрый вывод, чем PyTorch, или для обслуживания моделей с квантованием (FP8/INT4), пакетной обработкой в ​​реальном времени и масштабированием с использованием нескольких графических процессоров.
