使用推測性解碼、Medusa 多頭和前瞻解碼技術加速 LLM 推理。在優化推理速度（1.5-3.6 倍加速）、減少實時應用程序的延遲或部署計算有限的模型時使用。涵蓋草稿模型、基於樹的注意力、雅可比迭代、並行令牌生成和生產部署策略。
