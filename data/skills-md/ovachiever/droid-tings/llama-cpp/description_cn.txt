在 CPU、Apple Silicon 和消费类 GPU 上运行 LLM 推理，无需 NVIDIA 硬件。用于边缘部署、M1/M2/M3 Mac、AMD/Intel GPU 或 CUDA 不可用时。支持 GGUF 量化（1.5-8 位），以减少内存，与 CPU 上的 PyTorch 相比，速度提高 4-10 倍。
