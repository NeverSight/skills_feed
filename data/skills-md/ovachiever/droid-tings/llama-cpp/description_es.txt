Ejecuta inferencia LLM en CPU, Apple Silicon y GPU de consumo sin hardware NVIDIA. Úselo para implementación perimetral, Mac M1/M2/M3, GPU AMD/Intel o cuando CUDA no esté disponible. Admite la cuantificación GGUF (1,5-8 bits) para reducir la memoria y acelerar entre 4 y 10 veces en comparación con PyTorch en la CPU.
