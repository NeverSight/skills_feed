정확도 손실을 최소화하면서 LLM을 위한 사후 훈련 4비트 양자화. 2% 미만의 복잡성 저하로 4배의 메모리 감소가 필요한 경우 또는 FP16에 비해 더 빠른 추론(3-4배 속도 향상)이 필요한 경우 소비자 GPU에 대형 모델(70B, 405B)을 배포하는 데 사용합니다. QLoRA 미세 조정을 위해 변압기 및 PEFT와 통합됩니다.
