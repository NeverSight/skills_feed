Schnelle Tokenizer, optimiert für Forschung und Produktion. Rust-basierte Implementierung tokenisiert 1 GB in <20 Sekunden. Unterstützt BPE-, WordPiece- und Unigram-Algorithmen. Trainieren Sie benutzerdefinierte Vokabeln, verfolgen Sie Ausrichtungen und behandeln Sie Auffüllungen/Kürzungen. Lässt sich nahtlos in Transformatoren integrieren. Verwenden Sie es, wenn Sie eine leistungsstarke Tokenisierung oder ein benutzerdefiniertes Tokenizer-Training benötigen.
