Tokenizadores rápidos optimizados para investigación y producción. La implementación basada en Rust tokeniza 1 GB en <20 segundos. Admite algoritmos BPE, Wordpiece y Unigram. Entrene vocabularios personalizados, realice un seguimiento de las alineaciones y maneje el relleno/truncamiento. Se integra perfectamente con transformadores. Úselo cuando necesite tokenización de alto rendimiento o capacitación personalizada en tokenizadores.
