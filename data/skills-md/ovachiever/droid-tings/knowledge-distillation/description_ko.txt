교사에서 학생 모델로의 지식 증류를 사용하여 대규모 언어 모델을 압축합니다. 성능이 유지된 더 작은 모델을 배포하거나, GPT-4 기능을 오픈 소스 모델로 이전하거나, 추론 비용을 줄일 때 사용하세요. 온도 스케일링, 소프트 목표, 역 KLD, 로짓 증류 및 MiniLLM 교육 전략을 다룹니다.
