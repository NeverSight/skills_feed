Interroga tracce, prompt e metriche LLM di Langfuse. Utilizzare quando:
- Analisi delle tracce di generazione LLM (errori, latenza, token)
- Revisione delle prestazioni e delle versioni del prompt
- Debug delle generazioni fallite
- Confronto degli output del modello tra le esecuzioni
Parole chiave: langfuse, tracce, osservabilit√†, metriche LLM, gestione tempestiva, generazioni
