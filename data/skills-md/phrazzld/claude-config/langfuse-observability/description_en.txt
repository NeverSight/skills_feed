Query Langfuse traces, prompts, and LLM metrics. Use when:
- Analyzing LLM generation traces (errors, latency, tokens)
- Reviewing prompt performance and versions
- Debugging failed generations
- Comparing model outputs across runs
Keywords: langfuse, traces, observability, LLM metrics, prompt management, generations
