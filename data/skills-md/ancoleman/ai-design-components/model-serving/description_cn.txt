用于推理的 LLM 和 ML 模型部署。在生产中提供模型、构建 AI API 或优化推理时使用。涵盖 vLLM（LLM 服务）、TensorRT-LLM（GPU 优化）、Ollama（本地）、BentoML（ML 部署）、Triton（多模型）、LangChain（编排）、LlamaIndex (RAG) 和流模式。
