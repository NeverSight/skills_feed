추론을 위한 LLM 및 ML 모델 배포. 프로덕션에서 모델을 제공하거나 AI API를 구축하거나 추론을 최적화할 때 사용하세요. vLLM(LLM 제공), TensorRT-LLM(GPU 최적화), Ollama(로컬), BentoML(ML 배포), Triton(다중 모델), LangChain(오케스트레이션), LlamaIndex(RAG) 및 스트리밍 패턴을 다룹니다.
