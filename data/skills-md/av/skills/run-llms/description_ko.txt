[Harbor](https://github.com/av/harbor)를 사용하여 로컬 LLM을 설정하고 실행하기 위한 가이드입니다. 사용자가 LLM을 로컬에서 실행하고 Ollama, Open WebUI, llama.cpp, vLLM 또는 유사한 로컬 AI 서비스를 설정하려는 경우에 사용합니다. 모델 실행, 구성, 프로필, 터널 및 고급 기능을 통해 Docker 전제 조건의 전체 설정을 다룹니다.
