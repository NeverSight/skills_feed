使用 [Harbor](https://github.com/av/harbor) 設置和運行本地 LLM 的指南。當用戶想要在本地運行 LLM、設置 Ollama、Open WebUI、llama.cpp、vLLM 或類似的本地 AI 服務時使用。涵蓋從 Docker 先決條件到運行模型、配置、配置文件、隧道和高級功能的完整設置。
