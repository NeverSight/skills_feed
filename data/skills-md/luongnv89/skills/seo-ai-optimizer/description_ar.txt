يقوم بتدقيق قواعد الأكواد البرمجية لموقع الويب وتحسينها لمسح برامج تحسين محركات البحث (SEO) وروبوتات الذكاء الاصطناعي (AI). يغطي تحسين محركات البحث الفنية (العلامات الوصفية، وخرائط الموقع، وملف robots.txt، وعناوين URL الأساسية، وتلميحات سرعة الصفحة، والبيانات المنظمة)، وتحسين محركات البحث للمحتوى (بنية العنوان، والنص البديل، وسهولة القراءة)، وإمكانية الوصول إلى روبوت الذكاء الاصطناعي (توجيهات llms.txt، GPTBot/ClaudeBot، ai-plugin.json، Schema.org/JSON-LD). يُستخدم عندما يطلب المستخدم "تحسين تحسين محركات البحث"، أو "تدقيق تحسين محركات البحث"، أو "تحسين تصنيفات البحث"، أو "جعل الموقع صديقًا للذكاء الاصطناعي"، أو "إضافة بيانات منظمة"، أو "إصلاح العلامات الوصفية"، أو "التحسين لروبوتات الذكاء الاصطناعي". يعمل مع أي إطار ويب.
