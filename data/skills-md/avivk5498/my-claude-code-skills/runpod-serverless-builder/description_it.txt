Crea endpoint serverless RunPod pronti per la produzione con tempi di avvio a freddo ottimizzati. Da utilizzare durante la creazione o la modifica di nodi di lavoro serverless RunPod per (1) inferenza LLM basata su vLLM, (2) generazione di immagini/video ComfyUI o (3) inferenza Python personalizzata. Supporta sia i modelli cotti (avvii a freddo pi√π veloci) che il caricamento dinamico (modelli condivisi). Genera progetti completi tra cui Dockerfile, gestori di lavoro, script di avvio e configurazione ottimizzata per una latenza minima di avvio a freddo.
