透過 4 位元量化和 LoRA 適配器進行記憶體高效微調。當在消費性 GPU 上微調大型模型 (7B+)、VRAM 有限或標準 LoRA 仍超出記憶體時使用。以勞拉技能為基礎。
