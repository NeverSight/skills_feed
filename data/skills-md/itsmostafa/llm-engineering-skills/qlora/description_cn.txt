通过 4 位量化和 LoRA 适配器进行内存高效微调。当在消费类 GPU 上微调大型模型 (7B+)、VRAM 有限或标准 LoRA 仍超出内存时使用。以劳拉技能为基础。
