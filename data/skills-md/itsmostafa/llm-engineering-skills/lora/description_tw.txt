透過低秩適應 (LoRA) 進行參數高效微調。在使用有限的 GPU 記憶體微調大型語言模型、建立特定於任務的適配器或需要從單一基礎訓練多個專用模型時使用。
