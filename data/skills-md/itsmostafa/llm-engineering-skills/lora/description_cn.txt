通过低秩适应 (LoRA) 进行参数高效微调。在使用有限的 GPU 内存微调大型语言模型、创建特定于任务的适配器或需要从单个基础训练多个专用模型时使用。
