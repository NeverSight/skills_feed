Implementa l'osservabilità completa per le applicazioni LLM, tra cui tracciamento (Langfuse/Helicone), monitoraggio dei costi, ottimizzazione dei token, metriche di valutazione RAG (RAGAS), rilevamento delle allucinazioni e monitoraggio della produzione. Essenziale per il debug, l'ottimizzazione dei costi e la garanzia della qualità dell'output dell'intelligenza artificiale. Utilizzare quando viene menzionato ", monitoraggio llm, tracciamento, langfuse, helicone, monitoraggio dei costi, ragas, valutazione, rilevamento di allucinazioni, memorizzazione nella cache dei prompt".
