À utiliser pour réduire la taille du modèle, améliorer la vitesse d'inférence ou déployer sur des appareils de périphérie : couvre la quantification, l'élagage, la distillation des connaissances, l'exportation ONNX et l'optimisation TensorRT. À utiliser lorsque "", " est mentionné.
