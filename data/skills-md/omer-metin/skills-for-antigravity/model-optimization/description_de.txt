Wird verwendet, wenn die Modellgröße reduziert, die Inferenzgeschwindigkeit verbessert oder auf Edge-Geräten bereitgestellt wird – umfasst Quantisierung, Bereinigung, Wissensdestillation, ONNX-Export und TensorRT-Optimierung. Verwendung, wenn „“, „ erwähnt wird.
