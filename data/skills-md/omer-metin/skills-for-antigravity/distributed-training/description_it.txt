Da utilizzare per l'addestramento di modelli su più GPU o nodi, per la gestione di modelli di grandi dimensioni che non rientrano nella memoria o per l'ottimizzazione del throughput dell'addestramento: copre DDP, FSDP, DeepSpeed ​​ZeRO, parallelismo modello/dati e checkpoint del gradiente. Utilizzare quando "," menzionato.
