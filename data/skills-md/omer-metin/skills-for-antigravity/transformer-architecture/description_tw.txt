在實現注意力機制、構建自定義 Transformer 模型、理解位置編碼或優化 Transformer 推理時使用 - 涵蓋自註意力、多頭注意力、RoPE、ALiBi 和架構變體在提到“,”時使用。
