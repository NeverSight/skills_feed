在实现注意力机制、构建自定义 Transformer 模型、理解位置编码或优化 Transformer 推理时使用 - 涵盖自注意力、多头注意力、RoPE、ALiBi 和架构变体 当提到“,”时使用。
